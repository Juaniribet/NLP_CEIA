{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"data":{"text/plain":["array([list(['que', 'dia', 'es', 'hoy']),\n","       list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']),\n","       list(['martes', 'muchas', 'gracias'])], dtype=object)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["corpus_list = np.char.split(corpus)\n","corpus_list"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["array(['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas',\n","       'que'], dtype='<U7')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["vocabulary = np.unique(np.sum(corpus_list))\n","vocabulary"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"markdown","metadata":{},"source":["Uso de GPT-3.5\n","\n","Prompt : \"give me a python function that returns a one hot encoding matrix of a list of texts using only numpy\"\n","\n","\"This code defines a function one_hot_encode that takes a list of texts and an optional vocabulary as input. If a vocabulary is not provided, it constructs one from the unique words in the input texts. It then creates an empty one-hot encoding matrix and fills it based on the vocabulary and the words in the input texts. Finally, it returns the one-hot encoding matrix and the vocabulary.\n","\n","Note that the vocabulary is a list of unique words in the texts, and the one-hot encoding matrix has rows corresponding to each input text and columns corresponding to each word in the vocabulary\""]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["One-hot encoding matrix:\n","[[1. 1. 1. 0. 0. 0. 0. 1. 0.]\n"," [1. 1. 1. 0. 1. 1. 0. 0. 1.]\n"," [0. 0. 0. 1. 0. 1. 1. 0. 0.]]\n","\n","Vocabulary:\n","['hoy', 'es', 'dia', 'gracias', 'el', 'martes', 'muchas', 'que', 'de']\n"]}],"source":["def one_hot_encode(texts, vocab=None):\n","    if vocab is None:\n","        # Create a vocabulary from the unique words in the texts\n","        vocab = list(set(\" \".join(texts).split()))\n","\n","    # Create an empty one-hot encoding matrix\n","    one_hot_matrix = np.zeros((len(texts), len(vocab)))\n","\n","    # Create a dictionary to map words to their index in the vocabulary\n","    word_to_index = {word: i for i, word in enumerate(vocab)}\n","\n","    # Fill in the one-hot matrix\n","    for i, text in enumerate(texts):\n","        words = text.split()\n","        for word in words:\n","            # if word in word_to_index: # modifico codigo de GPT - Este if no es necesario en estos casos\n","            one_hot_matrix[i, word_to_index[word]] = 1\n","\n","    return one_hot_matrix, vocab\n","\n","# Example usage:\n","one_hot_matrix, vocab = one_hot_encode(corpus)\n","print(\"One-hot encoding matrix:\")\n","print(one_hot_matrix)\n","print(\"\\nVocabulary:\")\n","print(vocab)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0., 1., 0., 1., 0., 1., 0., 0., 1.],\n","       [1., 1., 1., 1., 0., 1., 1., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 1., 1., 0.]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["one_hot_matrix, _ = one_hot_encode(corpus, vocabulary)\n","one_hot_matrix"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"markdown","metadata":{},"source":["Uso de GPT-3.5\n","\n","Prompt : \"give me a python function that returns a frequency representation matrix of a list of texts using only numpy\"\n","\n","\"This code defines a function frequency_representation that takes a list of texts and an optional vocabulary as input. If a vocabulary is not provided, it constructs one from the unique words in the input texts. It then creates an empty frequency representation matrix and fills it based on the vocabulary and the words in the input texts. The matrix will contain the word frequencies for each word in each text. Finally, it returns the frequency representation matrix and the vocabulary.\n","\n","The vocabulary is a list of unique words in the texts, and the frequency representation matrix has rows corresponding to each input text and columns corresponding to each word in the vocabulary, with cell values representing word frequencies.\""]},{"cell_type":"code","execution_count":8,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["Frequency representation matrix:\n","[[1. 1. 1. 0. 0. 0. 0. 1. 0.]\n"," [1. 1. 1. 0. 1. 2. 0. 0. 1.]\n"," [0. 0. 0. 1. 0. 1. 1. 0. 0.]]\n","\n","Vocabulary:\n","['hoy', 'es', 'dia', 'gracias', 'el', 'martes', 'muchas', 'que', 'de']\n"]}],"source":["def frequency_representation(texts, vocab=None):\n","    if vocab is None:\n","        # Create a vocabulary from the unique words in the texts\n","        vocab = list(set(\" \".join(texts).split()))\n","\n","    # Create an empty frequency representation matrix\n","    freq_matrix = np.zeros((len(texts), len(vocab)))\n","\n","    # Create a dictionary to map words to their index in the vocabulary\n","    word_to_index = {word: i for i, word in enumerate(vocab)}\n","\n","    # Fill in the frequency matrix\n","    for i, text in enumerate(texts):\n","        words = text.split()\n","        for word in words:\n","            #if word in word_to_index: # modifico codigo de GPT - Este if no es necesario en estos casos\n","            freq_matrix[i, word_to_index[word]] += 1\n","\n","    return freq_matrix, vocab\n","\n","# Example usage:\n","freq_matrix, vocab = frequency_representation(corpus)\n","print(\"Frequency representation matrix:\")\n","print(freq_matrix)\n","print(\"\\nVocabulary:\")\n","print(vocab)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0., 1., 0., 1., 0., 1., 0., 0., 1.],\n","       [1., 1., 1., 1., 0., 1., 2., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 1., 1., 0.]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["freq_matrix, _ = frequency_representation(corpus, vocabulary)\n","freq_matrix"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"markdown","metadata":{},"source":["Uso de GPT-3.5\n","\n","Prompt : \"give me a python function that returns a matrix  representation Factor TF-IDF of a list of texts using only numpy\"\n","\n","\"This code performs the following steps:\n","\n","1. Builds a vocabulary from the unique words in the texts.\n","2. Calculates the term frequencies (TF) for each term in each document.\n","3. Computes the inverse document frequency (IDF) for each term.\n","4. Finally, it calculates the TF-IDF matrix using TF and IDF.\n","\n","Please note that this is a basic implementation of TF-IDF using NumPy, and it may not be as optimized or feature-rich as libraries like scikit-learn. In practice, using a library like scikit-learn is recommended for TF-IDF calculations due to its efficiency and extensive functionality.\""]},{"cell_type":"code","execution_count":10,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["TF-IDF representation matrix:\n","[[0.25       0.25       0.25       0.         0.         0.\n","  0.         0.35136628 0.        ]\n"," [0.14285714 0.14285714 0.14285714 0.         0.20078073 0.28571429\n","  0.         0.         0.20078073]\n"," [0.         0.         0.         0.46848837 0.         0.33333333\n","  0.46848837 0.         0.        ]]\n","\n","Vocabulary:\n","['hoy', 'es', 'dia', 'gracias', 'el', 'martes', 'muchas', 'que', 'de']\n"]}],"source":["# Modifique el codigo par que quede de la misma manera que las funciones anteriores.\n","\n","def tfidf_representation(texts, vocab=None):\n","    # Step 1: Create a vocabulary\n","    if vocab is None:\n","        # Create a vocabulary from the unique words in the texts\n","        vocab = list(set(\" \".join(texts).split()))\n","    \n","    # Step 2: Calculate term frequencies (TF)\n","    tf_matrix = np.zeros((len(texts), len(vocab)))\n","    for i, text in enumerate(texts):\n","        words = text.split()\n","        for j, word in enumerate(vocab):\n","            tf_matrix[i, j] = words.count(word) / len(words)\n","\n","    # Step 3: Calculate inverse document frequency (IDF)\n","    df = np.sum(tf_matrix > 0, axis=0)\n","    idf = np.log(len(texts) / (df + 1)) + 1\n","\n","    # Step 4: Calculate TF-IDF\n","    tfidf_matrix = tf_matrix * idf\n","\n","    return tfidf_matrix, vocab\n","\n","# Example usage:\n","tfidf_matrix, vocab = tfidf_representation(corpus)\n","print(\"TF-IDF representation matrix:\")\n","print(tfidf_matrix)\n","print(\"\\nVocabulary:\")\n","print(vocab)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.        , 0.25      , 0.        , 0.25      , 0.        ,\n","        0.25      , 0.        , 0.        , 0.35136628],\n","       [0.20078073, 0.14285714, 0.20078073, 0.14285714, 0.        ,\n","        0.14285714, 0.28571429, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.46848837,\n","        0.        , 0.33333333, 0.46848837, 0.        ]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["tfidf_matrix, _ = tfidf_representation(corpus, vocabulary)\n","tfidf_matrix"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def compare_cos(document, method = 'one_hot_encode'):\n","    # Se Codifica el documento\n","    if method == 'one_hot_encode':\n","        matrix,_ = one_hot_encode(document)\n","    if method == 'frequency_representation':\n","        matrix,_ = frequency_representation(document)\n","    if method == 'tfidf_representation':\n","        matrix,_ = tfidf_representation(document)\n","\n","    similitud = []\n","    # Realiza la comparación de cada elemento y lo guarda en 'similitud'\n","    for i in range(len(document)-1):\n","        for j in range(i,len(document)):\n","            if i!=j:\n","                similarity = cosine_similarity(matrix[i], matrix[j])\n","                similitud.append([i , j , similarity])\n","    similitud = np.array(similitud)\n","\n","    # Imprime los resultados\n","    for i in similitud:\n","        print(f'doc:{int(i[0])} con doc:{int(i[1])} tiene similitud de coseno de: {i[2]}')\n","    \n","    # Ordena los resultados por similitud de a pares\n","    similitud1 = similitud[similitud[:, 2].argsort()][::-1][:,:2].flatten()\n","    indexes = np.unique(similitud1, return_index=True)[1]\n","    index = [similitud1[index] for index in sorted(indexes)]\n","\n","    print('\\nOrden por similitud de mayor a menor:')\n","    for i in index:\n","        print(f'Documento {int(i)}: {document[int(i)]}')\n","    "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["doc:0 con doc:1 tiene similitud de coseno de: 0.6123724356957946\n","doc:0 con doc:2 tiene similitud de coseno de: 0.0\n","doc:1 con doc:2 tiene similitud de coseno de: 0.23570226039551587\n","\n","Orden por similitud de mayor a menor:\n","Documento 0: que dia es hoy\n","Documento 1: martes el dia de hoy es martes\n","Documento 2: martes muchas gracias\n"]}],"source":["compare_cos(corpus)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["doc:0 con doc:1 tiene similitud de coseno de: 0.5\n","doc:0 con doc:2 tiene similitud de coseno de: 0.0\n","doc:1 con doc:2 tiene similitud de coseno de: 0.3849001794597505\n","\n","Orden por similitud de mayor a menor:\n","Documento 0: que dia es hoy\n","Documento 1: martes el dia de hoy es martes\n","Documento 2: martes muchas gracias\n"]}],"source":["compare_cos(corpus, 'frequency_representation')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["doc:0 con doc:1 tiene similitud de coseno de: 0.40643395243330166\n","doc:0 con doc:2 tiene similitud de coseno de: 0.0\n","doc:1 con doc:2 tiene similitud de coseno de: 0.2716301798632699\n","\n","Orden por similitud de mayor a menor:\n","Documento 0: que dia es hoy\n","Documento 1: martes el dia de hoy es martes\n","Documento 2: martes muchas gracias\n"]}],"source":["compare_cos(corpus, 'tfidf_representation')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Cambienado el orden de los docs\n","corpus = np.array(['que dia es hoy', 'martes muchas gracias', 'martes el dia de hoy es martes'])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["doc:0 con doc:1 tiene similitud de coseno de: 0.0\n","doc:0 con doc:2 tiene similitud de coseno de: 0.6123724356957946\n","doc:1 con doc:2 tiene similitud de coseno de: 0.23570226039551587\n","\n","Orden por similitud de mayor a menor:\n","Documento 0: que dia es hoy\n","Documento 2: martes el dia de hoy es martes\n","Documento 1: martes muchas gracias\n"]}],"source":["compare_cos(corpus)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["doc:0 con doc:1 tiene similitud de coseno de: 0.0\n","doc:0 con doc:2 tiene similitud de coseno de: 0.5\n","doc:1 con doc:2 tiene similitud de coseno de: 0.3849001794597505\n","\n","Orden por similitud de mayor a menor:\n","Documento 0: que dia es hoy\n","Documento 2: martes el dia de hoy es martes\n","Documento 1: martes muchas gracias\n"]}],"source":["compare_cos(corpus, 'frequency_representation')"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["doc:0 con doc:1 tiene similitud de coseno de: 0.0\n","doc:0 con doc:2 tiene similitud de coseno de: 0.40643395243330166\n","doc:1 con doc:2 tiene similitud de coseno de: 0.2716301798632699\n","\n","Orden por similitud de mayor a menor:\n","Documento 0: que dia es hoy\n","Documento 2: martes el dia de hoy es martes\n","Documento 1: martes muchas gracias\n"]}],"source":["compare_cos(corpus, 'tfidf_representation')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
